# AutoML Micro Framework ğŸš€

A lightweight and modular AutoML framework for structured tabular datasets.  
This project allows users to run a complete ML pipeline (preprocessing, model selection, training, evaluation) with minimal configuration.

## âœ… Features

- Modern CLI based on [Typer](https://typer.tiangolo.com/)
- Automatic preprocessing (scaling, encoding, imputing)
- Dynamic model selection via config or CLI
- Train/Test splitting for realistic evaluation
- Model saving (`trained_model.pkl`)
- Metrics saving (`results.json`) for experiment tracking
- Modular structure, ready for extension (tuning, regression, API deployment)

## ğŸ”§ Quickstart

1. Clone the repository:
```bash
git clone https://github.com/yourusername/automl_micro.git
cd automl_micro
````

2. Create a virtual environment and install dependencies:

```bash
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. Prepare your CSV dataset.
   Ensure the target variable is correctly labeled and referenced inside `config/default.yaml`.

4. Run the pipeline via CLI:

```bash
python cli/main.py --dataset path/to/your.csv
```

Optional arguments:

* `--model_name`: override the model specified in the config
* `--config_path`: use a different YAML configuration
* `--output_dir`: customize the output directory for artifacts

Example:

```bash
python cli/main.py --dataset data/iris.csv --model_name logreg --output_dir my_results/
```

After running:

* The trained model will be saved inside the specified artifacts folder.
* The results (accuracy, model name, train/test sizes) will be appended to `results.json`.

## ğŸ“ Project Structure

```
automl_micro/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ preprocessing.py     # Preprocessing pipeline
â”‚   â”œâ”€â”€ model_selection.py    # Model selection logic
â”‚   â”œâ”€â”€ trainer.py             # Training and evaluation
â”‚   â”œâ”€â”€ saver.py               # Model saving
â”‚   â””â”€â”€ result_saver.py        # Saving run metrics
â”œâ”€â”€ cli/
â”‚   â”œâ”€â”€ main.py                # CLI entry point (Typer)
â”‚   â”œâ”€â”€ run_pipeline.py        # Pipeline orchestration
â”‚   â””â”€â”€ config_loader.py       # Configuration loader
â”œâ”€â”€ config/
â”‚   â””â”€â”€ default.yaml           # Default pipeline configuration
â”œâ”€â”€ artifacts/                 # (Created at runtime) Saved models and results
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ“Œ Configuration

Edit `config/default.yaml` to set:

* Target column
* Preprocessing strategies (scaling, encoding, imputation)
* Model name and hyperparameters
* Test set split ratio

Example:

```yaml
target: species

preprocessing:
  scaling: standard
  encoding: onehot
  imputation_num: mean
  imputation_cat: most_frequent

model:
  name: randomforest
  params:
    n_estimators: 100
    max_depth: 5

test_size: 0.2
```

## ğŸ§ª Coming soon

* Regression task support
* Hyperparameter tuning with Optuna
* Advanced preprocessing (outlier handling, feature engineering)
* Inference API (FastAPI endpoint)
* Experiment tracking dashboard

## ğŸ“Œ License

MIT License.
